#!/usr/bin/env python3
"""
åŠ¨æ€ç”Ÿæˆaccelerateé…ç½®æ–‡ä»¶
"""

import os
import sys
import yaml
import torch
from pathlib import Path

def detect_gpu_count():
    """æ£€æµ‹å¯ç”¨GPUæ•°é‡"""
    try:
        if torch.cuda.is_available():
            return torch.cuda.device_count()
        else:
            return 0
    except Exception:
        return 0

def generate_accelerate_config(num_gpus, mixed_precision="fp16", output_path="default_config.yaml"):
    """ç”Ÿæˆaccelerateé…ç½®"""
    
    if num_gpus <= 0:
        # CPUé…ç½®
        config = {
            "compute_environment": "LOCAL_MACHINE",
            "distributed_type": "NO",
            "downcast_bf16": "no",
            "machine_rank": 0,
            "main_training_function": "main",
            "mixed_precision": "no",
            "num_machines": 1,
            "num_processes": 1,
            "use_cpu": True
        }
    elif num_gpus == 1:
        # å•GPUé…ç½®
        config = {
            "compute_environment": "LOCAL_MACHINE", 
            "distributed_type": "NO",
            "downcast_bf16": "no",
            "gpu_ids": "0",
            "machine_rank": 0,
            "main_training_function": "main",
            "mixed_precision": mixed_precision,
            "num_machines": 1,
            "num_processes": 1,
            "use_cpu": False
        }
    else:
        # å¤šGPUé…ç½®
        config = {
            "compute_environment": "LOCAL_MACHINE",
            "distributed_type": "MULTI_GPU", 
            "downcast_bf16": "no",
            "gpu_ids": "all",
            "machine_rank": 0,
            "main_training_function": "main",
            "mixed_precision": mixed_precision,
            "num_machines": 1,
            "num_processes": min(num_gpus, 8),  # æœ€å¤šä½¿ç”¨8ä¸ªGPU
            "rdzv_backend": "static",
            "same_network": True,
            "tpu_env": [],
            "tpu_use_cluster": False,
            "tpu_use_sudo": False,
            "use_cpu": False
        }
    
    # ä¿å­˜é…ç½®æ–‡ä»¶
    project_root = Path(__file__).parent.parent
    config_path = project_root / output_path
    
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    return config_path, config

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="ç”Ÿæˆaccelerateé…ç½®æ–‡ä»¶")
    parser.add_argument("--num_gpus", type=int, default=-1, help="GPUæ•°é‡ (-1è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹)")
    parser.add_argument("--mixed_precision", type=str, default="fp16", 
                       choices=["no", "fp16", "bf16"], help="æ··åˆç²¾åº¦ç±»å‹")
    parser.add_argument("--output", type=str, default="default_config.yaml", 
                       help="è¾“å‡ºé…ç½®æ–‡ä»¶å")
    
    args = parser.parse_args()
    
    # æ£€æµ‹æˆ–ä½¿ç”¨æŒ‡å®šçš„GPUæ•°é‡
    if args.num_gpus == -1:
        num_gpus = detect_gpu_count()
        print(f"ğŸ” è‡ªåŠ¨æ£€æµ‹GPUæ•°é‡: {num_gpus}")
    else:
        num_gpus = args.num_gpus
        print(f"ğŸ“ ä½¿ç”¨æŒ‡å®šGPUæ•°é‡: {num_gpus}")
    
    # ç”Ÿæˆé…ç½®
    config_path, config = generate_accelerate_config(
        num_gpus, args.mixed_precision, args.output
    )
    
    print(f"âœ… é…ç½®æ–‡ä»¶å·²ç”Ÿæˆ: {config_path}")
    print(f"ğŸ“Š é…ç½®å†…å®¹:")
    print(f"   - åˆ†å¸ƒå¼ç±»å‹: {config.get('distributed_type', 'N/A')}")
    print(f"   - è¿›ç¨‹æ•°: {config.get('num_processes', 'N/A')}")
    print(f"   - æ··åˆç²¾åº¦: {config.get('mixed_precision', 'N/A')}")
    print(f"   - GPUè®¾å¤‡: {config.get('gpu_ids', 'N/A')}")
    
    # å»ºè®®ä½¿ç”¨å‘½ä»¤
    if num_gpus > 1:
        print(f"\nğŸš€ æ¨èåˆ†å¸ƒå¼è®­ç»ƒå‘½ä»¤:")
        print(f"   accelerate launch --config_file {args.output} scripts/train.py [è®­ç»ƒå‚æ•°]")
    elif num_gpus == 1:
        print(f"\nğŸš€ æ¨èå•GPUè®­ç»ƒå‘½ä»¤:")
        print(f"   python scripts/train.py [è®­ç»ƒå‚æ•°]")
    else:
        print(f"\nğŸš€ æ¨èCPUè®­ç»ƒå‘½ä»¤:")
        print(f"   python scripts/train.py --device cpu [è®­ç»ƒå‚æ•°]")

if __name__ == "__main__":
    main()